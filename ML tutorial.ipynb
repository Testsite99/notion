{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f02bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import collections\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "644fb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Books_small_10000.json')\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for line in f:\n",
    "    data = json.loads(line)\n",
    "    review = data[\"reviewText\"]\n",
    "    score = data[\"overall\"]\n",
    "    if score <= 2:\n",
    "        sentiment = \"NEGATIVE\"\n",
    "        reviews.append((review, sentiment))\n",
    "    elif score > 3:\n",
    "        sentiment = \"POSITIVE\"\n",
    "        reviews.append((review, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2ef1d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 9022\n",
      "Positive proportion: 92.86189315007759\n",
      "Negative proportion: 7.138106849922411\n"
     ]
    }
   ],
   "source": [
    "print(\"Total:\", len(reviews))\n",
    "\n",
    "print(\"Positive proportion:\", (len([line for line in reviews if line[1] == \"POSITIVE\"])/len(reviews))*100)\n",
    "\n",
    "print(\"Negative proportion:\", (len([line for line in reviews if line[1] == \"NEGATIVE\"])/len(reviews))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ebc423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive proportion: 50.0\n",
      "Negative proportion: 50.0\n"
     ]
    }
   ],
   "source": [
    "target_length = len([line for line in reviews if line[1] == \"NEGATIVE\"])\n",
    "\n",
    "reviews_negative = [line for line in reviews if line[1] == \"NEGATIVE\"]\n",
    "reviews_positive = [line for line in reviews if line[1] == \"POSITIVE\"]\n",
    "\n",
    "reviews_new = reviews_negative + reviews_positive[:target_length]\n",
    "\n",
    "print(\"Positive proportion:\", (len([line for line in reviews_new if line[1] == \"POSITIVE\"])/len(reviews_new))*100)\n",
    "\n",
    "print(\"Negative proportion:\", (len([line for line in reviews_new if line[1] == \"NEGATIVE\"])/len(reviews_new))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "715b4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "\n",
    "training, test = train_test_split(reviews_new, test_size = 0.33, random_state=42)\n",
    "\n",
    "train_x = [line[0] for line in training]\n",
    "train_y = [line[1] for line in training]\n",
    "\n",
    "test_x = [line[0] for line in test]\n",
    "test_y = [line[1] for line in test]\n",
    "\n",
    "## TfidfVectorizer gives weights to words that are mentioned less -> different to CountVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7abcfdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM: 0.8497652582159625\n"
     ]
    }
   ],
   "source": [
    "## SVM\n",
    "\n",
    "clf_svm = svm.SVC(kernel = \"linear\")\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "print(\"Accuracy of SVM:\", clf_svm.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a92ae4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of decision tree: 0.6854460093896714\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "print(\"Accuracy of decision tree:\", clf_dec.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e98583fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "print(\"Accuracy of logistic regression:\", clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e72046b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: [0.84236453 0.         0.85650224]\n",
      "Decision trees: [0.69124424 0.         0.67942584]\n",
      "Logistic regression: [0.82808717 0.         0.83826879]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mquick\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\mquick\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\mquick\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"SVM\", \"Decision trees\", \"Logistic regression\"]\n",
    "y_predicts = [clf_svm.predict(test_x_vectors),\n",
    "              clf_dec.predict(test_x_vectors),\n",
    "              clf_log.predict(test_x_vectors)]\n",
    "\n",
    "for name, y_predict in zip(model_names, y_predicts):\n",
    "    print(f\"{name}:\", f1_score(test_y, y_predict, average = None, labels = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eea98c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'POSITIVE': '82.4%', 'NEGATIVE': '7.0%', 'NEUTRAL': '10.6%'})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(train_y)\n",
    "\n",
    "total = sum(counter.values())\n",
    "\n",
    "for key in counter.keys():\n",
    "    val = counter[key]\n",
    "    prop = (val/total)*100\n",
    "    counter[key] = f'{round(prop,1)}%'\n",
    "    \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ab11320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([i for i in range(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4218e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 2, 3, 4), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": tuple([i for i in range(1,5)])}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8fdfe8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf_svm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d9e89a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"models_test.pkl\", \"rb\") as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b1ea00c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28539af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
